# train.py
from datasets import load_dataset
from earvas_model_self import EarVAS                 # å¤åˆ»çš„æ¨¡å‹ï¼Œæœ‰å·®å¼‚
# from EarVAS_models import EarVAS                 # æ¥è‡ªå¼€æºé¡¹ç›® 
from dataset_hf import EarVASDatasetFromHF      # è‡ªå·±å†™çš„ï¼Œå¤„ç†æ•°æ®æº
# from dataset_lazy_split import CachedEarVASDataset
# from dataset_cached import CachedEarVASDataset

from torch.utils.data import DataLoader
import torch
import torch.nn as nn
import torch.optim as optim
from tqdm import tqdm
import multiprocessing
from monitor import monitor_system
from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, matthews_corrcoef, confusion_matrix
import numpy as np
from fvcore.nn import FlopCountAnalysis, parameter_count
import pandas as pd
import os
from sklearn.preprocessing import label_binarize
from fvcore.nn import FlopCountAnalysis, parameter_count
import datetime 
import shutil 
import time
import torch.multiprocessing as mp 

import random

# ========= é…ç½®åŒºåŸŸ =========
use_freRA_in_train = True 
batch_size = 128  
num_epochs = 15
return_alpha = True # æ˜¯å¦è¿”å› alpha åˆ†æ•°

# Early Stopping é…ç½®
early_stop_patience = 5           # å¿è€è½®æ•°
warmup_epochs = 10                # å‰å‡ è½®ä¸åˆ¤æ–­æ—©åœ

# ========= åˆå§‹åŒ–ï¼ŒåŸºæœ¬ä¸ç”¨æ”¹åŠ¨ =========
# Early Stopping ç›¸å…³
val_loss_history = []            # å­˜æ”¾æœ€è¿‘ val loss
max_history = early_stop_patience
no_improve_epochs = 0            # æœªæ”¹å–„è®¡æ•°å™¨

# ä¸è®­ç»ƒæ— å…³
timestamp = datetime.datetime.now().strftime("%Y-%m-%d_%H%M") # è·å–å½“å‰æ—¶é—´ä½œä¸ºå­æ–‡ä»¶å¤¹ï¼Œä¾‹å¦‚ '2025-05-09_0320'
save_dir = os.path.join('model', 'earvas_self', timestamp) # åˆ›å»ºå¸¦æ—¶é—´æˆ³çš„ä¿å­˜ç›®å½•

PROJECT_ROOT = os.environ.get("PROJECT_ROOT", None)
if not PROJECT_ROOT:
    PROJECT_ROOT = os.path.abspath(".")
#=========

def set_seed(seed=42):
    random.seed(seed)                          # Python åŸç”Ÿéšæœºæ•°
    np.random.seed(seed)                       # NumPy éšæœºæ•°
    torch.manual_seed(seed)                    # PyTorch CPU éšæœºæ•°
    torch.cuda.manual_seed(seed)               # GPU éšæœºæ•°ï¼ˆå•GPUè¶³å¤Ÿï¼‰
    torch.backends.cudnn.deterministic = True  # ä½¿ç”¨ç¡®å®šæ€§ç®—æ³•
    torch.backends.cudnn.benchmark = False     # å…³é—­è‡ªåŠ¨ä¼˜åŒ–ç®—æ³•ï¼ˆæé«˜å¯é‡å¤æ€§ï¼‰

def main(): 
    set_seed(42)  # å›ºå®šéšæœºç§å­ï¼Œæé«˜å¯å¤ç°æ€§
    mp.set_start_method("spawn", force=True) # è®¾ç½®å¤šè¿›ç¨‹å¯åŠ¨æ–¹æ³•
    num_workers = min(16, os.cpu_count() // 2)   # 8 ??? æ”¹æˆmin(config.num_workers, os.cpu_count() // 2)
    print("num_workers:", num_workers) 
 
# åŠ è½½æ•°æ®é›†
    print("\n==================== åŠ è½½ HF æ•°æ®é›† ====================")
    dataset = load_dataset("THU-PI-Sensing/DreamCatcher", "sleep_event_classification", trust_remote_code=True)
    label_names = dataset["train"].features["label"].names
    # train_dataset = EarVASDatasetFromHF(dataset["train"]) 
    # val_dataset = EarVASDatasetFromHF(dataset["validation"])
    # test_dataset = EarVASDatasetFromHF(dataset["test"])
    train_dataset = EarVASDatasetFromHF(dataset["train"], apply_freRA=False)
    val_dataset   = EarVASDatasetFromHF(dataset["validation"], apply_freRA=False)
    test_dataset  = EarVASDatasetFromHF(dataset["test"], apply_freRA=False)
 
    
    # print("\n==================== è¯»å–ç¼“å­˜æ•°æ®é›† ====================")
    # preprocesssed_data_dir = "preprocessed_DC/1" # 10000æ ·æœ¬ä¸€ä¸ªpt
    # preprocesssed_data_dir = "preprocessed_DreamCatcher" # å•æ¡æ ·æœ¬ä¸€ä¸ªpt

    # æå‰æŒªåˆ°æœ¬åœ° SSDï¼Œå‡å°‘ NFS è¯»å–æ—¶é—´ã€å¥½åƒæ•ˆæœä¸å¤§ã€‘
    # if "TMPDIR" in os.environ: # æ£€æŸ¥æ˜¯å¦åœ¨ GLab ç¯å¢ƒï¼ˆæ˜¯å¦æœ‰æœ¬åœ° SSD ä¸´æ—¶ç›®å½•ï¼‰
    #     tmp_data_root = os.environ["TMPDIR"]
    #     tmp_data_dir = os.path.join(PROJECT_ROOT, tmp_data_root, "preprocessed_DC")

    #     if not os.path.exists(tmp_data_dir):
    #         print(f"ğŸ“¦ å¤åˆ¶é¢„å¤„ç†æ•°æ®åˆ°æœ¬åœ° SSD: {tmp_data_dir}ï¼ˆè¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼‰")
    #         t0 = time.time()
    #         shutil.copytree("preprocessed_DC", tmp_data_dir)
    #         print(f"âœ… å®Œæˆå¤åˆ¶ï¼Œç”¨æ—¶ {time.time() - t0:.1f} ç§’")
    #     else:
    #         print(f"ğŸ“‚ æœ¬åœ° SSD å·²å­˜åœ¨é¢„å¤„ç†æ•°æ®: {tmp_data_dir}")
    # else:
    #     tmp_data_dir = "preprocessed_DC"
    #     print("âš ï¸ æœªæ£€æµ‹åˆ° TMPDIRï¼Œä»ç„¶ä½¿ç”¨ NFS ç›®å½•") 
    # ä½¿ç”¨æœ¬åœ°è·¯å¾„æ„é€  Dataset  âœ… é’ˆå¯¹lazy_split
    # preprocesssed_data_dir = os.path.join(PROJECT_ROOT, tmp_data_dir, "1")  # æ³¨æ„ åŸå§‹ç›®å½•ç»“æ„æ˜¯ preprocessed_DC/1

    # é’ˆå¯¹dataset_cached
    # train_dataset = CachedEarVASDataset(preprocesssed_data_dir, "train") # ä½¿ç”¨ç¼“å­˜æ•°æ®é›†
    # val_dataset = CachedEarVASDataset(preprocesssed_data_dir, "validation")
    # test_dataset = CachedEarVASDataset(preprocesssed_data_dir, "test")
    # âœ… é’ˆå¯¹lazy_split
    # train_dataset = CachedEarVASDataset(preprocesssed_data_dir, "train", apply_freRA=True) # ä½¿ç”¨ç¼“å­˜æ•°æ®é›†
    # val_dataset = CachedEarVASDataset(preprocesssed_data_dir, "validation", apply_freRA=False)
    # test_dataset = CachedEarVASDataset(preprocesssed_data_dir, "test", apply_freRA=False)


# æ„å»º PyTorch Dataset å’Œ DataLoader
    print("\n==================== æ„å»ºPyTorch Dataset å’Œ DataLoader ====================")
    train_loader = DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=num_workers,     # ä½¿ç”¨ CPU æ ¸å¿ƒæ•°çš„ä¸€åŠ
        pin_memory=True
    ) 
    val_loader = DataLoader(
        val_dataset,
        batch_size=batch_size, # 64,   # ä½ å¯ä»¥è®¾ç½®ç­‰äºè®­ç»ƒ batch_size
        num_workers=num_workers,
        pin_memory=True
    )

#     # åˆå§‹åŒ–æ¨¡å‹ï¼šæµ‹è¯•æœ€ç®€å•çš„æ¨¡å‹
#         # model = EarVAS(num_classes=9)
#         # # æµ‹è¯• forward
#         # for audio, imu, label in train_loader:
#         #     print("ğŸ§ audio shape:", audio.shape)  # (4, 2, 512, 128)
#         #     print("ğŸ“ˆ imu shape:", imu.shape)      # (4, 6, 100)
#         #     print("ğŸ¯ label:", label.shape)        # (4, )
            
#         #     output = model(audio, imu)
#         #     print("ğŸ§  model output:", output.shape)  # (4, 9)
#         #     break

# åˆå§‹åŒ–
    print("\n==================== åˆå§‹åŒ–è®¾å¤‡å’Œæ¨¡å‹ ====================")
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = EarVAS(num_classes=9, use_freRA=use_freRA_in_train).to(device)     # âœ… ä½¿ç”¨è‡ªåˆ¶ EarVAS æ¨¡å‹
    # è¿”å›çš„æ˜¯ä¸€ä¸ª PyTorch æ¨¡å‹å¯¹è±¡ï¼Œç»§æ‰¿è‡ª torch.nn.Module, æ„é€ äº†ä¸€ä¸ªç¥ç»ç½‘ç»œç»“æ„å›¾
    # å°†æ¨¡å‹ç§»åŠ¨åˆ°æŒ‡å®šè®¾å¤‡
    print("âœ… å½“å‰è®¾å¤‡ï¼š", device)
    print("âœ… æ¨¡å‹è®¾å¤‡ï¼š", next(model.parameters()).device)

    # âœ… æŸå¤±å‡½æ•° & ä¼˜åŒ–å™¨
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=1e-4)

    # âœ… è¯„ä¼°å‡½æ•°
    @torch.no_grad()
    def evaluate_model(model, val_loader, device):
        print("\n==================== è¿›å…¥è¯„ä¼°å‡½æ•° evaluate_model ====================")
        model.eval()
        model.to(device)  # ç¡®ä¿æ¨¡å‹ä¹Ÿåœ¨ GPU
        print("evaluate_model æ¨¡å‹å½“å‰æ‰€åœ¨è®¾å¤‡ï¼š", next(model.parameters()).device)
        all_preds, all_labels = [], []

        total_loss = 0.0
        for step, (audio, imu, labels) in enumerate(val_loader):
            # if step >= 30: # ğŸ‘ˆ åªè·‘å‰ 3 ä¸ª batch, ä»¥ä¾¿debug
            #     break   
            audio, imu, labels = audio.to(device), imu.to(device), labels.to(device)

            # # âœ… åªåœ¨ç¬¬ä¸€ä¸ª batch åˆ†ææ¨¡æ€èŒƒæ•°å·®å¼‚
            # if step == 0:
            #     try:
            #         # Audio ç‰¹å¾
            #         audio_feat = model.audio_model(audio)
            #         audio_feat = model.audio_proj(audio_feat)

            #         # IMU ç‰¹å¾
            #         if hasattr(model, "freRA") and model.use_freRA:
            #             imu = model.freRA(imu)
            #         imu_feat = model.imu_branch(imu)

            #         audio_norm = audio_feat.norm(dim=1)
            #         imu_norm = imu_feat.norm(dim=1)

            #         print(f"\nğŸ§ audio_feat mean norm: {audio_norm.mean().item():.4f}")
            #         print(f"ğŸ“ˆ imu_feat mean norm:   {imu_norm.mean().item():.4f}")
            #         print(f"ğŸ“ å¹³å‡å·®å€¼:             {(audio_norm.mean() - imu_norm.mean()).item():.4f}")
            #         print(f"ğŸ“ å¹³å‡ç»å¯¹å·®ï¼ˆæ ·æœ¬çº§ï¼‰: {(audio_norm - imu_norm).abs().mean().item():.4f}")
            #     except Exception as e:
            #         print("âš ï¸ æ¨¡æ€èŒƒæ•°åˆ†æå¤±è´¥ï¼š", e)

            # æ­£å¸¸æ¨ç†
            outputs, alpha = model(audio, imu, return_alpha=return_alpha) # outputs = model(audio, imu)
            preds = torch.argmax(outputs, dim=1)
            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())
            # ä¸ºäº†æ—©åœè€Œè®¡ç®—loss
            loss = criterion(outputs, labels)  
            total_loss += loss.item()

            # æ¯ä¸ª epoch åªæ‰“å°ä¸€æ¬¡ alpha åˆ†å¸ƒï¼ˆç¬¬ä¸€ä¸ª batchï¼‰
            if step == 0:
                print(f"ğŸ“Š alpha: mean={alpha.mean():.4f}, min={alpha.min():.4f}, max={alpha.max():.4f}")
        print("evaluate_model å†…å¾ªç¯å®Œäº†")

        acc = accuracy_score(all_labels, all_preds)
        f1 = f1_score(all_labels, all_preds, average='macro')
        mcc = matthews_corrcoef(all_labels, all_preds)

        num_classes = dataset["train"].features["label"].num_classes
        labels = list(range(num_classes))
        cm = confusion_matrix(all_labels, all_preds, labels=labels)

        avg_val_loss = total_loss / len(val_loader)   # ä¸ºäº†æ—©åœ æ–°å¢
        # ğŸ¯ Macro-AUC
        try:
            y_true_bin = label_binarize(all_labels, classes=list(range(num_classes)))
            y_pred_bin = label_binarize(all_preds, classes=list(range(num_classes)))
            auc = roc_auc_score(y_true_bin, y_pred_bin, average="macro", multi_class="ovr")
        except:
            auc = -1  # fail-safe

        return {
            "accuracy": acc,
            "f1": f1,
            "confusion_matrix": cm,
            "mcc": mcc,
            "auc": auc,
            "val_loss": avg_val_loss               # ğŸ‘ˆ æ–°å¢
        }
 

# å¦‚æœæƒ³åªç”¨testï¼Œæ³¨é‡Šæ‰è¿™éƒ¨åˆ†-----
    # æ‰¾æœ€ä½³æ¨¡å‹
    best_f1 = 0.0
    best_acc = 0.0
    best_val_loss = float("inf") 
    
    dirs = os.path.join(PROJECT_ROOT, save_dir)
    os.makedirs(dirs, exist_ok=True)

    # âœ… å¼€å§‹è®­ç»ƒå¾ªç¯
    print("\n==================== è¿›å…¥train ====================")
    for epoch in range(num_epochs):
        model.train()
        total_loss = 0.0
        loop = tqdm(train_loader, desc=f"Epoch {epoch+1}/{num_epochs}", unit="batch", mininterval=20, maxinterval=60)

        for step, (audio, imu, labels) in enumerate(loop):
            # if step >= 300:  # ğŸ‘ˆ åªè·‘å‰ 3 ä¸ª batch, ä»¥ä¾¿debug
            #     break

            t0 = time.time() 
            #  æ•°æ®è½¬ç§»åˆ° GPU
            audio = audio.to(device)     # [B, 2, 512, 128]
            imu = imu.to(device)         # [B, 6, 100]
            labels = labels.to(device)   # [B]
            t1 = time.time()

            optimizer.zero_grad()

            # âœ… å‰å‘ä¼ æ’­
            outputs = model(audio, imu)  # [B, 9]
            loss = criterion(outputs, labels)
            t2 = time.time()

            # âœ… åå‘ä¼ æ’­ + æ›´æ–°
            loss.backward()
            optimizer.step()
            t3 = time.time()

            total_loss += loss.item()

            #  æ‰“å°è¯¦ç»†è€—æ—¶ Epoch 1/10:   2%|â– | 42/2313 [09:31<7:47:56, 12.36s/batch, loss=0.8083, load=0.00s, fwd=0.01s, bwd=0.01s]  é—®é¢˜ä¸å¤§
            if step % 10 == 0:
                loop.set_postfix({
                    "loss": f"{loss.item():.4f}",
                    "load": f"{t1 - t0:.2f}s",
                    "fwd": f"{t2 - t1:.2f}s",
                    "bwd": f"{t3 - t2:.2f}s"
                }) 
            # loop.set_postfix(loss=loss.item())

        avg_loss = total_loss / len(train_loader)
        print(f"[Epoch {epoch+1}] âœ… Average Loss: {avg_loss:.4f}")

        # âœ… éªŒè¯é›†è¯„ä¼°
        results = evaluate_model(model, val_loader, device)
        acc, f1, cm = results["accuracy"], results["f1"], results["confusion_matrix"]
        df_cm = pd.DataFrame(cm, index=label_names, columns=label_names)
            
        print(f"[Epoch {epoch+1}] ğŸ¯ Accuracy: {acc:.4f} | F1: {f1:.4f}")
        print(f"[Epoch {epoch+1}] ğŸ“Š Confusion Matrix:\n{cm}")

        val_loss = results.get("val_loss", 0)   # ä¸ºäº†æ—©åœ åˆå§‹åŒ–
        
        # âœ… ä¿å­˜æœ€ä½³æ¨¡å‹
        if f1 > best_f1: # ä»¥f1ä¸ºå‡†
            best_f1 = f1
        # if acc > best_acc: # ä»¥accä¸ºå‡†
            # best_acc = acc
            no_improve_epochs = 0 
            save_path = os.path.join(PROJECT_ROOT, save_dir, f"epoch{epoch+1}_f1_{f1:.4f}_acc_{acc:.4f}.pt")
            torch.save({
                'epoch': epoch,
                'model_state': model.state_dict(),
                'optimizer_state': optimizer.state_dict(),
                'f1': f1,
                'accuracy': acc
            }, save_path)
            print(f"ğŸ’¾ Saved best model at epoch {epoch+1} with F1 = {f1:.4f}, accuracy = {acc:.4f}")
        else:
            # æœ¬æ¬¡æ¨¡å‹æ•ˆæœä¸‹é™
            no_improve_epochs += 1
            print(f"[Epoch {epoch+1}] âŒ F1æ— æå‡ï¼ˆ+{f1 - best_f1:.4f}ï¼‰ï¼Œå¿è€è®¡æ•°: {no_improve_epochs}/{early_stop_patience}")

            # Early stopping åˆ¤æ–­ï¼ˆè·³è¿‡ warmupï¼‰
            if epoch + 1 <= warmup_epochs: 
                print(f"[Epoch {epoch+1}] â³ Warmupä¸­ï¼Œä¸åˆ¤æ–­æ—©åœ")
                continue

            # â• è®°å½• val_loss è¶‹åŠ¿
            val_loss_history.append(val_loss)
            if len(val_loss_history) > max_history:
                val_loss_history.pop(0) 
            
            if val_loss < best_val_loss - 1e-6:
                best_val_loss = val_loss # ä»¥æ•´ä¸ªè®­ç»ƒè¿‡ç¨‹çš„æœ€å° loss ä¸ºæœ€ä½³ã€‚
            # ğŸ¯ Early stop æ¡ä»¶ï¼šF1 è¿ç»­ä¸æå‡ + val_loss ä¸Šå‡
            if no_improve_epochs >= early_stop_patience and all(x >= best_val_loss for x in val_loss_history):
                print("â¹ï¸ Early stopping: F1 æ— æ”¹å–„ï¼Œä¸” val_loss æŒç»­æœªä¸‹é™")
                break
# ---
    print("\n==================== è¿›å…¥test ====================")
    test_loader = DataLoader(test_dataset, batch_size=batch_size)  # 32

    def safe_load_model(model, path, device="cpu"):
        try: # å°è¯•ç›´æ¥åŠ è½½ä¸º state_dict
            state_dict = torch.load(path, map_location=device)
            model.load_state_dict(state_dict)
            print(f"âœ… ç›´æ¥åŠ è½½æ¨¡å‹æƒé‡æˆåŠŸï¼š{path}")
        except RuntimeError as e:
            print("âš ï¸ å°è¯•ç›´æ¥åŠ è½½å¤±è´¥ï¼Œå¯èƒ½æ˜¯ checkpoint åŒ…å«é¢å¤–ä¿¡æ¯ï¼Œæ˜¯å­—å…¸ï¼Œåˆ‡æ¢åˆ° checkpoint['model_state'] æ–¹å¼")
            try:
                checkpoint = torch.load(path, map_location=device)
                model.load_state_dict(checkpoint["model_state"])
                print(f"âœ… ä» checkpoint['model_state'] åŠ è½½æˆåŠŸï¼š{path}")
            except Exception as e2:
                print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥ï¼š{e2}")
                raise RuntimeError("æ¨¡å‹æ–‡ä»¶æ ¼å¼ä¸å…¼å®¹ï¼Œè¯·ç¡®è®¤æ˜¯å¦ä¿å­˜äº†æ­£ç¡®çš„ state_dict æˆ– checkpoint")
        return model

    # âœ… åŠ è½½æœ€ä¼˜æ¨¡å‹
    # model_path = "epoch7_f1_0.4924_acc_0.7277.pt"
    # save_path = os.path.join(PROJECT_ROOT, 'model/earvas_self/2025-05-09_0522', model_path)
    print(f"\n==================== åŠ è½½æœ€ä¼˜æ¨¡å‹ echoæ€»æ¬¡æ•°:{num_epochs} æ¨¡å‹åç§°:{save_path}====================")
    # print("ğŸ”¥ PyTorch ç¼–è¯‘æ—¶ç”¨çš„ CUDA ç‰ˆæœ¬", torch.version.cuda) # PyTorch ç¼–è¯‘æ—¶ç”¨çš„ CUDA ç‰ˆæœ¬
    # print("ğŸ”¥ æ˜¯å¦æ£€æµ‹åˆ° GPU:", torch.cuda.is_available())
    # print("ğŸ”¥ å½“å‰å¯ç”¨ GPU æ•°é‡:", torch.cuda.device_count())
    # print("ğŸ”¥ å½“å‰ä½¿ç”¨è®¾å¤‡:", device)

    model = safe_load_model(model, save_path, device)
    model.to(device)

    # âœ… æ·»åŠ  FLOPs & å‚æ•°é‡ç»Ÿè®¡ï¼ˆå»ºè®®åœ¨ test å‰åªè®¡ç®—ä¸€æ¬¡ï¼‰
    dummy_audio = torch.randn(1, 2, 512, 128).to(device)
    dummy_imu = torch.randn(1, 6, 100).to(device)

    flops = FlopCountAnalysis(model, (dummy_audio, dummy_imu))
    params = parameter_count(model)[""]

    print(f"ğŸ§® FLOPs: {flops.total() / 1e9:.2f} GFLOPs")
    print(f"ğŸ§® Params: {params / 1e6:.2f} M")

    # âœ… æµ‹è¯•è¯„ä¼°
    print("\n==================== æµ‹è¯•çš„è¯„ä¼° ing ====================") 
    results = evaluate_model(model, test_loader, device)

    df_cm = pd.DataFrame(results['confusion_matrix'], index=label_names, columns=label_names)

    print("\n==================== ğŸ§ª Final Evaluation ====================")
    print(f"{save_path}\n")
    print(f"ğŸ¯ Accuracy:   {results['accuracy']:.4f}")
    print(f"ğŸ¯ Macro-AUC:  {results['auc']:.4f}")
    print(f"ğŸ¯ Macro-F1:   {results['f1']:.4f}")
    print(f"ğŸ¯ MCC:        {results['mcc']:.4f}")
    print(f"ğŸ§® FLOPs:      {flops.total() / 1e9:.2f} GFLOPs")
    print(f"ğŸ§® Params:     {params / 1e6:.2f} M")
    print(f"ğŸ“Š Test Confusion Matrix:\n{df_cm}")

    # ä¿å­˜ confusion matrix
    confusion_csv_path = os.path.join(PROJECT_ROOT, "confusion_matrix.csv")
    df_cm.to_csv(confusion_csv_path, index=True)
    # ä¿å­˜è¯„ä¼°æŒ‡æ ‡
    metrics_path = os.path.join(PROJECT_ROOT, "metrics.txt")
    with open(metrics_path, "a") as f:
        f.write(f"{save_path}\n")
        f.write(f"Accuracy:   {results['accuracy']:.4f}\n")
        f.write(f"Macro-AUC:  {results['auc']:.4f}\n")
        f.write(f"Macro-F1:   {results['f1']:.4f}\n")
        f.write(f"MCC:        {results['mcc']:.4f}\n")
        f.write(f"FLOPs:      {flops.total() / 1e9:.2f} GFLOPs\n")
        f.write(f"Params:     {params / 1e6:.2f} M\n")
        f.write(f"Confusion Matrix:\n{df_cm.to_string()}\n")

if __name__ == "__main__":  
    print("\n==================== å¼€å§‹åå°ç›‘æ§ ====================") 
    MONITOR_FILE = os.path.join(PROJECT_ROOT, f"monitor_log/monitor_log_{timestamp}.txt")
    monitor_process = multiprocessing.Process(target=monitor_system, args=(60, MONITOR_FILE )) # æ¯ 60 ç§’è®°å½•ä¸€æ¬¡çŠ¶æ€
    monitor_process.start()

    try: 
        main()
    except Exception as e:
        print("âŒ æŠ¥é”™å•¦ï¼š", e)
        raise
    finally:  # æ— è®ºæ˜¯å¦æŠ¥é”™ï¼Œéƒ½ç»ˆæ­¢å­è¿›ç¨‹
        #  åœæ­¢ç³»ç»Ÿç›‘æ§
        monitor_process.terminate()
        monitor_process.join()
        print("\n==================== è„šæœ¬ç»“æŸ ====================")